{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47e522cb-2dd4-4946-ba60-d6356d8bf076",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Clinical-AI-Apollo/Medical-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Clinical-AI-Apollo/Medical-NER\")\n",
    "# Load data\n",
    "file_path = r\"C:\\Users\\Michael\\Downloads\\NER\\comments.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "df = df.iloc[:1000]\n",
    "patient_comments_col = 'careprovidercomments'\n",
    "unique_entities_results = 'Unique Entities'\n",
    "total_words_results = 'Total Words'\n",
    "specificity_results = 'Specificity Score'\n",
    "\n",
    "specificity_scores = []\n",
    "unique_entities_list = []\n",
    "total_words_list = []\n",
    "\n",
    "# Define a function to tokenize and align predictions with labels\n",
    "def tokenize_and_predict(text):\n",
    "    # Tokenize the input text\n",
    "    tokenized_inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "    word_ids = tokenized_inputs.word_ids(batch_index=0)  # Word IDs map tokens back to words in the original text\n",
    "\n",
    "    # Perform predictions\n",
    "    outputs = model(**tokenized_inputs)\n",
    "    predictions = torch.argmax(outputs.logits, dim=2)\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(tokenized_inputs[\"input_ids\"][0])\n",
    "    labels = [model.config.id2label[p.item()] for p in predictions[0]]\n",
    "\n",
    "    aligned_labels = []\n",
    "    previous_word_idx = None\n",
    "\n",
    "    # Align predicted labels to tokens\n",
    "    for word_idx, label in zip(word_ids, labels):\n",
    "        if word_idx is None:\n",
    "            aligned_labels.append(-100)  # Skip special tokens\n",
    "        elif word_idx != previous_word_idx:\n",
    "            aligned_labels.append(label)  # Label for the start of each new word\n",
    "        else:\n",
    "            aligned_labels.append(-100)  # Continue label alignment for subwords\n",
    "        previous_word_idx = word_idx\n",
    "\n",
    "    # Pair tokens with their corresponding labels\n",
    "    token_label_pairs = [(token, label) for token, label in zip(tokens, aligned_labels) if label != -100]\n",
    "    return token_label_pairs\n",
    "\n",
    "def calculate_specificity(text):\n",
    "    token_label_pairs = tokenize_and_predict(text)\n",
    "    entity_list = []\n",
    "    total_words = len(text.split())\n",
    "    entity_count = 0\n",
    "    for token, label in token_label_pairs:\n",
    "        if label != \"O\":\n",
    "            entity_count += 1\n",
    "            entity_list.append(label)\n",
    "    return entity_count/total_words, entity_list, total_words\n",
    "\n",
    "for comment in df[patient_comments_col]:\n",
    "    if isinstance(comment, str):  # Ensure that the comment is a string\n",
    "        specificity_score, unique_entities, total_words = calculate_specificity(comment)\n",
    "        \n",
    "        # Append the results to the respective lists\n",
    "        specificity_scores.append(specificity_score)\n",
    "        unique_entities_list.append(unique_entities)\n",
    "        total_words_list.append(total_words)\n",
    "    else:\n",
    "        specificity_scores.append(0)\n",
    "        unique_entities_list.append([])\n",
    "        total_words_list.append(0)\n",
    "\n",
    "\n",
    "df[specificity_results] = specificity_scores\n",
    "df[unique_entities_results] = unique_entities_list\n",
    "df[total_words_results] = total_words_list\n",
    "\n",
    "columns_to_keep = ['ID', 'unidentifiableid', 'Combined_Sentiment', 'Combined_Wait',\n",
    "       'Updated_Wait',\n",
    "       'BERT_Sentiment', 'BERT_Wait', 'BERT_MistakeMedical', 'careprovidercomments',\n",
    "       'Medical_Mistakes', 'Clerical_Mistakes', 'Communication_Mistakes', 'Unique Entities', 'Total Words', 'Specificity Score']\n",
    "df = df[columns_to_keep]\n",
    "df.to_excel(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "228ee9fe-e7e4-4609-99e5-f9f264388f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities recognized by the model:\n",
      "O\n",
      "\n",
      "\n",
      "\n",
      "B-ACTIVITY\n",
      "\n",
      "\n",
      "\n",
      "I-ACTIVITY\n",
      "\n",
      "\n",
      "\n",
      "I-ADMINISTRATION\n",
      "\n",
      "\n",
      "\n",
      "B-ADMINISTRATION\n",
      "\n",
      "\n",
      "\n",
      "B-AGE\n",
      "\n",
      "\n",
      "\n",
      "I-AGE\n",
      "\n",
      "\n",
      "\n",
      "I-AREA\n",
      "\n",
      "\n",
      "\n",
      "B-AREA\n",
      "\n",
      "\n",
      "\n",
      "B-BIOLOGICAL_ATTRIBUTE\n",
      "\n",
      "\n",
      "\n",
      "I-BIOLOGICAL_ATTRIBUTE\n",
      "\n",
      "\n",
      "\n",
      "I-BIOLOGICAL_STRUCTURE\n",
      "\n",
      "\n",
      "\n",
      "B-BIOLOGICAL_STRUCTURE\n",
      "\n",
      "\n",
      "\n",
      "B-CLINICAL_EVENT\n",
      "\n",
      "\n",
      "\n",
      "I-CLINICAL_EVENT\n",
      "\n",
      "\n",
      "\n",
      "B-COLOR\n",
      "\n",
      "\n",
      "\n",
      "I-COLOR\n",
      "\n",
      "\n",
      "\n",
      "I-COREFERENCE\n",
      "\n",
      "\n",
      "\n",
      "B-COREFERENCE\n",
      "\n",
      "\n",
      "\n",
      "B-DATE\n",
      "\n",
      "\n",
      "\n",
      "I-DATE\n",
      "\n",
      "\n",
      "\n",
      "I-DETAILED_DESCRIPTION\n",
      "\n",
      "\n",
      "\n",
      "B-DETAILED_DESCRIPTION\n",
      "\n",
      "\n",
      "\n",
      "I-DIAGNOSTIC_PROCEDURE\n",
      "\n",
      "\n",
      "\n",
      "B-DIAGNOSTIC_PROCEDURE\n",
      "\n",
      "\n",
      "\n",
      "I-DISEASE_DISORDER\n",
      "\n",
      "\n",
      "\n",
      "B-DISEASE_DISORDER\n",
      "\n",
      "\n",
      "\n",
      "B-DISTANCE\n",
      "\n",
      "\n",
      "\n",
      "I-DISTANCE\n",
      "\n",
      "\n",
      "\n",
      "B-DOSAGE\n",
      "\n",
      "\n",
      "\n",
      "I-DOSAGE\n",
      "\n",
      "\n",
      "\n",
      "I-DURATION\n",
      "\n",
      "\n",
      "\n",
      "B-DURATION\n",
      "\n",
      "\n",
      "\n",
      "I-FAMILY_HISTORY\n",
      "\n",
      "\n",
      "\n",
      "B-FAMILY_HISTORY\n",
      "\n",
      "\n",
      "\n",
      "B-FREQUENCY\n",
      "\n",
      "\n",
      "\n",
      "I-FREQUENCY\n",
      "\n",
      "\n",
      "\n",
      "I-HEIGHT\n",
      "\n",
      "\n",
      "\n",
      "B-HEIGHT\n",
      "\n",
      "\n",
      "\n",
      "B-HISTORY\n",
      "\n",
      "\n",
      "\n",
      "I-HISTORY\n",
      "\n",
      "\n",
      "\n",
      "I-LAB_VALUE\n",
      "\n",
      "\n",
      "\n",
      "B-LAB_VALUE\n",
      "\n",
      "\n",
      "\n",
      "I-MASS\n",
      "\n",
      "\n",
      "\n",
      "B-MASS\n",
      "\n",
      "\n",
      "\n",
      "I-MEDICATION\n",
      "\n",
      "\n",
      "\n",
      "B-MEDICATION\n",
      "\n",
      "\n",
      "\n",
      "I-NONBIOLOGICAL_LOCATION\n",
      "\n",
      "\n",
      "\n",
      "B-NONBIOLOGICAL_LOCATION\n",
      "\n",
      "\n",
      "\n",
      "I-OCCUPATION\n",
      "\n",
      "\n",
      "\n",
      "B-OCCUPATION\n",
      "\n",
      "\n",
      "\n",
      "B-OTHER_ENTITY\n",
      "\n",
      "\n",
      "\n",
      "I-OTHER_ENTITY\n",
      "\n",
      "\n",
      "\n",
      "B-OTHER_EVENT\n",
      "\n",
      "\n",
      "\n",
      "I-OTHER_EVENT\n",
      "\n",
      "\n",
      "\n",
      "I-OUTCOME\n",
      "\n",
      "\n",
      "\n",
      "B-OUTCOME\n",
      "\n",
      "\n",
      "\n",
      "I-PERSONAL_BACKGROUND\n",
      "\n",
      "\n",
      "\n",
      "B-PERSONAL_BACKGROUND\n",
      "\n",
      "\n",
      "\n",
      "B-QUALITATIVE_CONCEPT\n",
      "\n",
      "\n",
      "\n",
      "I-QUALITATIVE_CONCEPT\n",
      "\n",
      "\n",
      "\n",
      "I-QUANTITATIVE_CONCEPT\n",
      "\n",
      "\n",
      "\n",
      "B-QUANTITATIVE_CONCEPT\n",
      "\n",
      "\n",
      "\n",
      "B-SEVERITY\n",
      "\n",
      "\n",
      "\n",
      "I-SEVERITY\n",
      "\n",
      "\n",
      "\n",
      "B-SEX\n",
      "\n",
      "\n",
      "\n",
      "I-SEX\n",
      "\n",
      "\n",
      "\n",
      "B-SHAPE\n",
      "\n",
      "\n",
      "\n",
      "I-SHAPE\n",
      "\n",
      "\n",
      "\n",
      "B-SIGN_SYMPTOM\n",
      "\n",
      "\n",
      "\n",
      "I-SIGN_SYMPTOM\n",
      "\n",
      "\n",
      "\n",
      "B-SUBJECT\n",
      "\n",
      "\n",
      "\n",
      "I-SUBJECT\n",
      "\n",
      "\n",
      "\n",
      "B-TEXTURE\n",
      "\n",
      "\n",
      "\n",
      "I-TEXTURE\n",
      "\n",
      "\n",
      "\n",
      "B-THERAPEUTIC_PROCEDURE\n",
      "\n",
      "\n",
      "\n",
      "I-THERAPEUTIC_PROCEDURE\n",
      "\n",
      "\n",
      "\n",
      "I-TIME\n",
      "\n",
      "\n",
      "\n",
      "B-TIME\n",
      "\n",
      "\n",
      "\n",
      "B-VOLUME\n",
      "\n",
      "\n",
      "\n",
      "I-VOLUME\n",
      "\n",
      "\n",
      "\n",
      "I-WEIGHT\n",
      "\n",
      "\n",
      "\n",
      "B-WEIGHT\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Clinical-AI-Apollo/Medical-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Clinical-AI-Apollo/Medical-NER\")\n",
    "\n",
    "entity_labels = model.config.id2label.values()\n",
    "print(\"Entities recognized by the model:\")\n",
    "for label in entity_labels:\n",
    "    print(label)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8788ef7-6747-4acc-83ab-1026095abb8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
